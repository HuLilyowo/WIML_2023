{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wKgKqVv-h8Y"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q torch\n",
        "!pip install --upgrade -q tensorflow\n",
        "!pip install --upgrade -q jax\n",
        "!pip install --upgrade -q keras-nlp\n",
        "!pip install --upgrade -q keras\n",
        "\n",
        "# Some care is required to install Keras 3. This is a temporary situation.\n",
        "# See installation notes at the end of this notebook for details."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Backend selection and display utilities [run me]\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def big_print(a,b):\n",
        "  html = '<div style=\"font-size: 18pt; font-family: monospace\">{}{}</div>'.format(a, b)\n",
        "  display(HTML(html))\n",
        "def plot_images(images):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "backend = 'tensorflow' # @param [\"jax\", \"tensorflow\", \"torch\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1inHlyswm8Rw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, os, random\n",
        "os.environ['KERAS_BACKEND'] = backend\n",
        "\n",
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "backend = keras.config.backend()\n",
        "big_print('\\u2B50 ', 'Keras version '+keras.version())\n",
        "big_print('\\u2B50 ', 'Running on '+backend.upper())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "ocq2Mjximt4K",
        "outputId": "d205deac-8c9c-4e0e-a1d2-9065740bb4f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"font-size: 18pt; font-family: monospace\">‚≠ê Keras version 3.0.0</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"font-size: 18pt; font-family: monospace\">‚≠ê Running on TENSORFLOW</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>\n",
        "\n",
        "# <img src=\"https://keras.io/img/k-logo.png\" height=\"80pt\" align=\"center\"/> Keras 3: Let us checkout a generative model and build a chatbot - OPT causal\n",
        "\n",
        "OPT is a causal language model, it continues the input prompt."
      ],
      "metadata": {
        "id": "6TtQuSdBnNzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "keras.utils.set_random_seed(42)\n",
        "nlp_model = keras_nlp.models.OPTCausalLM.from_preset(\"opt_125m_en\")\n",
        "nlp_model.compile(sampler=keras_nlp.samplers.ContrastiveSampler())"
      ],
      "metadata": {
        "id": "fOf0GM-fnR5s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Hi, I'm a {} machine learning developer. \\\n",
        "          What are you working on?\".format(backend.upper())\n",
        "response = nlp_model.generate(prompt, max_length=57)\n",
        "response = response.replace(prompt, '')\n",
        "big_print(\"\\U0001F64B \",prompt)\n",
        "big_print(\"\\U0001F916 \",response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "HCWEc_xxnaEA",
        "outputId": "e7754425-b087-413c-edf6-d52a8e49aa60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"font-size: 18pt; font-family: monospace\">üôã Hi, I'm a TENSORFLOW machine learning developer.           What are you working on?</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"font-size: 18pt; font-family: monospace\">ü§ñ \n",
              "A lot of things, I'm working on a couple of projects at the moment.</div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}